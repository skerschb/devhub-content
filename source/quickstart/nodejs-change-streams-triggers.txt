:template: devhub-article

.. ---------------------------------------------------------------
.. META FIELDS FOR SEO / SOCIAL
.. ---------------------------------------------------------------

.. meta-description:: 

   Discover how to react to changes in your MongoDB database using change streams implemented in Node.js and Atlas triggers.

.. twitter::
   :site: @mongodb
   :creator: @Lauren_Schaefer
   :title: Change Streams & Triggers with Node.js Tutorial
   :image: https://webassets.mongodb.com/_com_assets/cms/QuickStart-Node.js(Blog)-min-6pjap3h00s.png

   Discover how to react to changes in your MongoDB database using change streams implemented in Node.js and Atlas triggers.

.. ---------------------------------------------------------------
.. ARTICLE METADATA FIELDS (TO POPULATE FILTERS AND ARTICLE PAGE)
.. ---------------------------------------------------------------

.. include:: /includes/authors/schaefer-lauren.rst

.. pubdate:: January 8, 2020

.. updated-date:: February 18, 2020

.. type:: quickstart

.. level:: beginner

.. tags:: 

   * Node.js

.. languages::

   * JavaScript

.. products::

   * MongoDB
   * Atlas

.. atf-image:: /images/atf-images/quickstart/nodejs.png

.. related::

   * `How to connect to a MongoDB database using Node.js <https://www.mongodb.com/blog/post/quick-start-nodejs-mongodb--how-to-get-connected-to-your-database>`_
   * `MongoDB Node.js CRUD Tutorial </quickstart/java-setup-crud-operations>`_
   * `How to analyze your data using MongoDB’s Aggregation Framework and Node.js <https://www.mongodb.com/blog/post/quick-start-nodejs--mongodb--how-to-analyze-data-using-the-aggregation-framework>`_
   * `How to implement transactions using Node.js <https://www.mongodb.com/blog/post/quick-start-nodejs--mongodb--how-to-implement-transactions>`_

.. ---------------------------------------------------------------
.. ARTICLE CONTENT
.. ---------------------------------------------------------------

===============================================
Change Streams & Triggers with Node.js Tutorial
===============================================
 
.. introduction::

    .. image:: /images/quickstart-node.png
      :alt: QuickStart for Node.js Logo
      :scale: 30%
      :align: right

    Sometimes you need to react immediately to changes in your database.
    Perhaps you want to place an order with a distributor whenever an item’s
    inventory drops below a given threshold. Or perhaps you want to send an
    email notification whenever the status of an order changes. Regardless
    of your particular use case, whenever you want to react immediately to
    changes in your MongoDB database, change streams and triggers are
    fantastic options.

    If you’re just joining us in this Quick Start with MongoDB and Node.js
    series, welcome! We began by walking through how to `connect to
    MongoDB <https://www.mongodb.com/blog/post/quick-start-nodejs-mongodb--how-to-get-connected-to-your-database>`_
    and perform each of the
    `CRUD (create, read, update, and delete) Operations </quickstart/nodejs-crud-tutorial>`_.
    Then we jumped into more advanced topics like the `aggregation
    framework <https://www.mongodb.com/blog/post/quick-start-nodejs--mongodb--how-to-analyze-data-using-the-aggregation-framework>`_
    and
    `transactions <https://www.mongodb.com/blog/post/quick-start-nodejs--mongodb--how-to-implement-transactions>`_.
    The code we write today will use the same structure as the code we built
    in the first post in the series, so, if you have any questions about how
    to get started or how the code is structured, `head back to that
    post <https://www.mongodb.com/blog/post/quick-start-nodejs-mongodb--how-to-get-connected-to-your-database>`_.

    And, with that, let’s dive into change streams and triggers! Here is a
    summary of what we’ll cover today:

    -  :ref:`node-change-streams-what-are-change-streams`
    -  :ref:`node-change-streams-set-up`
    -  :ref:`node-change-streams-create-a-change-stream`
    -  :ref:`node-change-streams-resume`
    -  :ref:`node-change-streams-triggers`
    -  :ref:`node-change-streams-create-trigger`
    -  :ref:`node-change-streams-wrapping-up`
    -  :ref:`node-change-streams-resources`
    -  :ref:`node-change-streams-versions`
    -  :ref:`node-change-streams-series-toc`

    .. blockquote::

        Get started with an M0 cluster on `Atlas <http://bit.ly/MDB_Atlas>`_
        today. It’s free forever, and it’s the easiest way to try out the steps
        in this blog series.

.. content::

    .. _node-change-streams-what-are-change-streams:

    What are Change Streams?
    ------------------------

    Change streams allow you to receive notifications about changes made to
    your MongoDB databases and collections. When you use change streams, you
    can choose to program actions that will be automatically taken whenever
    a change event occurs.

    Change streams utilize the aggregation framework, so you can choose to
    filter for specific change events or transform the change event
    documents.

    For example, let’s say I want to be notified whenever a new listing in
    the Sydney, Australia market is added to the **listingsAndReviews**
    collection. I could create a change stream that monitors the
    **listingsAndReviews** collection and use an `aggregation
    pipeline <https://www.mongodb.com/blog/post/quick-start-nodejs--mongodb--how-to-analyze-data-using-the-aggregation-framework>`_
    to match on the listings I’m interested in.

    Let’s take a look at three different ways to implement this change
    stream.

    .. _node-change-streams-set-up:

    Set Up
    ------

    As with all posts in this MongoDB and Node.js Quick Start series, you’ll
    need to ensure you’ve completed the prerequisite steps outlined in the
    **Set up** section of the `first post in this
    series <https://www.mongodb.com/blog/post/quick-start-nodejs-mongodb--how-to-get-connected-to-your-database>`_.

    I find it helpful to have a script that will generate sample data when
    I’m testing change streams. To help you quickly generate sample data, I
    wrote
    `changeStreamsTestData.js <https://github.com/mongodb-developer/nodejs-quickstart/blob/master/changeStreamsTestData.js>`_.
    Download a copy of the file, update the ``uri`` constant to reflect your
    Atlas connection info, and run it by executing
    ``node changeStreamsTestData.js``. The script will do the following: 
    
    #. Create 3 new listings (Opera House Views, Private room in London, and
       Beautiful Beach House) 
    #. Update 2 of those listings (Opera House Views
       and Beautiful Beach House) 
    #. Create 2 more listings (Italian Villa and Sydney Harbour Home) 
    #. Delete a listing (Sydney Harbour Home).

    .. _node-change-streams-create-a-change-stream:

    Create a Change Stream
    ----------------------

    

    Now that we’re set up, let’s explore three different ways to work with a
    change stream in Node.js.

    Get a Copy of the Node.js Template
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

    

    To make following along with this blog post easier, I’ve created a
    starter template for a Node.js script that accesses an Atlas cluster.

    #. Download a copy of `template.js <https://github.com/mongodb-developer/nodejs-quickstart/blob/master/template.js>`_.
    #. Open template.js in your favorite code editor.
    #. Update the Connection URI to point to your Atlas cluster. If you’re not sure how to do that, refer back to `the first post in this series <https://www.mongodb.com/blog/post/quick-start-nodejs-mongodb--how-to-get-connected-to-your-database>`_.
    #. Save the file as ``changeStreams.js``.

    You can run this file by executing ``node changeStreams.js`` in your
    shell. At this point, the file simply opens and closes a connection to
    your Atlas cluster, so no output is expected. If you see
    DeprecationWarnings, you can ignore them for the purposes of this post.

    Create a Helper Function to Close the Change Stream
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

    

    Regardless of how we monitor changes in our change stream, we will want
    to close the change stream after a certain amount of time. Let’s create
    a helper function to do just that.

    #. Paste the following function in ``changeStreams.js``.

       .. code-block:: javascript

          function closeChangeStream(timeInMs = 60000, changeStream) {
              return new Promise((resolve) => {
                  setTimeout(() => {
                      console.log("Closing the change stream");
                      changeStream.close();
                      resolve();
                  }, timeInMs)
              })
          };


    Monitor Change Stream using EventEmitter’s on()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

    The MongoDB Node.js Driver’s ChangeStream class inherits from the Node
    Built-in class
    `EventEmitter <https://nodejs.org/dist/latest-v12.x/docs/api/events.html#events_class_eventemitter>`_.
    As a result, we can use EventEmitter’s
    `on() <https://nodejs.org/dist/latest-v12.x/docs/api/events.html#events_emitter_on_eventname_listener>`_
    function to add a listener function that will be called whenever a
    change occurs in the change stream.

    Create the Function
    ^^^^^^^^^^^^^^^^^^^

    Let’s create a function that will monitor changes in the change stream
    using EventEmitter’s ``on()``.

    #. Continuing to work in ``changeStreams.js``, create an asynchronous
       function named ``monitorListingsUsingEventEmitter``. The function
       should have the following parameters: a connected MongoClient, a time
       in ms that indicates how long the change stream should be monitored,
       and an aggregation pipeline that the change stream will use.

       .. code-block:: javascript

          async function monitorListingsUsingEventEmitter(client, timeInMs = 60000, pipeline = []){  

          }

    #. Now we need to access the collection we will monitor for changes. Add
       the following code to ``monitorListingsUsingEventEmitter()``.

       .. code-block:: javascript

         const collection = client.db("sample_airbnb").collection("listingsAndReviews");

    #. Now we are ready to create our change stream. We can do so by using
       `Collection <http://bit.ly/Node_Collection>`_\ ’s
       `watch() <http://bit.ly/Node_watch>`_. Add the following line
       beneath the existing code in ``monitorListingsUsingEventEmitter()``.
       
       .. code-block:: javascript  
       
          const changeStream = collection.watch(pipeline);

    #. Once we have our change stream, we can add a listener to it. Let’s
       log each change event in the console. Add the following line beneath
       the existing code in ``monitorListingsUsingEventEmitter()``.
       
       .. code-block:: javascript

          changeStream.on('change', (next) => {
               console.log(next);  
          });

    #. We could choose to leave the change stream open indefinitely.
       Instead, let’s call our helper function to set a timer and close the
       change stream. Add the following line beneath the existing code in
       ``monitorListingsUsingEventEmitter()``.

       .. code-block:: javascript

          await closeChangeStream(timeInMs, changeStream);


    Call the Function
    ^^^^^^^^^^^^^^^^^

    Now that we’ve implemented our function, let’s call it!

    #. Inside of ``main()`` beneath the comment that says
       ``Make the appropriate DB calls``, call your
       ``monitorListingsUsingEventEmitter()`` function:
       
       .. code-block:: javascript
       
         await monitorListingsUsingEventEmitter(client);

    #. Save your file.
    #. Run your script by executing ``node changeStreams.js`` in your shell.
       The change stream will open for 60 seconds.
    #. Create and update sample data by executing :ref:`node changeStreamsTestData.js <node-change-streams-set-up>` in a new shell. Output similar
       to the following will be displayed in your first shell where you are
       running ``changeStreams.js``.

       .. _node-change-streams-output:

       .. code-block:: javascript

          { _id:
              { _data:
              '825DE67A42000000012B022C0100296E5A10046BBC1C6A9CBB4B6E9CA9447925E693EF46645F696400645DE67A42113EA7DE6472E7640004' },
              operationType: 'insert',
              clusterTime:
              Timestamp { _bsontype: 'Timestamp', low_: 1, high_: 1575385666 },
              fullDocument:
              { _id: 5de67a42113ea7de6472e764,
              name: 'Opera House Views',
              summary:
                  'Beautiful apartment with views of the iconic Sydney Opera House',
              property_type: 'Apartment',
              bedrooms: 1,
              bathrooms: 1,
              beds: 1,
              address: { market: 'Sydney', country: 'Australia' } },
              ns: { db: 'sample_airbnb', coll: 'listingsAndReviews' },
              documentKey: { _id: 5de67a42113ea7de6472e764 } }
          { _id:
              { _data:
                  '825DE67A42000000022B022C0100296E5A10046BBC1C6A9CBB4B6E9CA9447925E693EF46645F696400645DE67A42113EA7DE6472E7650004' },
              operationType: 'insert',
              clusterTime:
              Timestamp { _bsontype: 'Timestamp', low_: 2, high_: 1575385666 },
              fullDocument:
              { _id: 5de67a42113ea7de6472e765,
              name: 'Private room in London',
              property_type: 'Apartment',
              bedrooms: 1,
              bathroom: 1 },
              ns: { db: 'sample_airbnb', coll: 'listingsAndReviews' },
              documentKey: { _id: 5de67a42113ea7de6472e765 } }
          { _id:
              { _data:
                  '825DE67A42000000032B022C0100296E5A10046BBC1C6A9CBB4B6E9CA9447925E693EF46645F696400645DE67A42113EA7DE6472E7660004' },
              operationType: 'insert',
              clusterTime:
              Timestamp { _bsontype: 'Timestamp', low_: 3, high_: 1575385666 },
              fullDocument:
              { _id: 5de67a42113ea7de6472e766,
              name: 'Beautiful Beach House',
              summary:
                  'Enjoy relaxed beach living in this house with a private beach',
              bedrooms: 4,
              bathrooms: 2.5,
              beds: 7,
              last_review: 2019-12-03T15:07:46.730Z },
              ns: { db: 'sample_airbnb', coll: 'listingsAndReviews' },
              documentKey: { _id: 5de67a42113ea7de6472e766 } }
           { _id:
              { _data:
                  '825DE67A42000000042B022C0100296E5A10046BBC1C6A9CBB4B6E9CA9447925E693EF46645F696400645DE67A42113EA7DE6472E7640004' },
              operationType: 'update',
              clusterTime:
              Timestamp { _bsontype: 'Timestamp', low_: 4, high_: 1575385666 },
              ns: { db: 'sample_airbnb', coll: 'listingsAndReviews' },
              documentKey: { _id: 5de67a42113ea7de6472e764 },
              updateDescription: { updatedFields: { beds: 2 }, removedFields: [] } }
           { _id:
              { _data:
                  '825DE67A42000000052B022C0100296E5A10046BBC1C6A9CBB4B6E9CA9447925E693EF46645F696400645DE67A42113EA7DE6472E7660004' },
              operationType: 'update',
              clusterTime:
              Timestamp { _bsontype: 'Timestamp', low_: 5, high_: 1575385666 },
              ns: { db: 'sample_airbnb', coll: 'listingsAndReviews' },
              documentKey: { _id: 5de67a42113ea7de6472e766 },
              updateDescription: { updatedFields: { address: [Object] }, removedFields: [] } }
           { _id:
              { _data:
                  '825DE67A42000000062B022C0100296E5A10046BBC1C6A9CBB4B6E9CA9447925E693EF46645F696400645DE67A42113EA7DE6472E7670004' },
              operationType: 'insert',
              clusterTime:
              Timestamp { _bsontype: 'Timestamp', low_: 6, high_: 1575385666 },
              fullDocument:
              { _id: 5de67a42113ea7de6472e767,
              name: 'Italian Villa',
              property_type: 'Entire home/apt',
              bedrooms: 6,
              bathrooms: 4,
              address: { market: 'Cinque Terre', country: 'Italy' } },
              ns: { db: 'sample_airbnb', coll: 'listingsAndReviews' },
              documentKey: { _id: 5de67a42113ea7de6472e767 } }
           { _id:
              { _data:
                  '825DE67A42000000072B022C0100296E5A10046BBC1C6A9CBB4B6E9CA9447925E693EF46645F696400645DE67A42113EA7DE6472E7680004' },
              operationType: 'insert',
              clusterTime:
              Timestamp { _bsontype: 'Timestamp', low_: 7, high_: 1575385666 },
              fullDocument:
              { _id: 5de67a42113ea7de6472e768,
              name: 'Sydney Harbour Home',
              bedrooms: 4,
              bathrooms: 2.5,
              address: { market: 'Sydney', country: 'Australia' } },
              ns: { db: 'sample_airbnb', coll: 'listingsAndReviews' },
              documentKey: { _id: 5de67a42113ea7de6472e768 } }
           { _id:
              { _data:
                  '825DE67A42000000082B022C0100296E5A10046BBC1C6A9CBB4B6E9CA9447925E693EF46645F696400645DE67A42113EA7DE6472E7680004' },
              operationType: 'delete',
              clusterTime:
              Timestamp { _bsontype: 'Timestamp', low_: 8, high_: 1575385666 },
              ns: { db: 'sample_airbnb', coll: 'listingsAndReviews' },
              documentKey: { _id: 5de67a42113ea7de6472e768 } }

       If you run the ``node changeStreamsTestData.js`` again before the 60
       second timer has completed, you will see similar output.

       After 60 seconds, the following will be displayed:

       .. code-block:: sh

          Closing the change stream
    

    Call the Function with an Aggregation Pipeline
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

    In some cases, you will not care about all change events that occur in a
    collection. Instead, you will want to limit what changes you are
    monitoring. You can use an aggregation pipeline to filter the changes or
    transform the change stream event documents.

    In our case, we only care about new listings in the Sydney, Australia
    market. Let’s create an aggregation pipeline to filter for only those
    changes in the ``listingsAndReviews`` collection.

    To learn more about what aggregation pipeline stages can be used
    with change streams, see the `official change streams
    documentation <https://docs.mongodb.com/manual/changeStreams/#modify-change-stream-output>`_.

    #. Inside of ``main()`` and above your existing call to
       ``monitorListingsUsingEventEmitter()``, create an aggregation
       pipeline:

       .. code-block:: javascript

           const pipeline = [
                       {
                           '$match': {
                               'operationType': 'insert',
                               'fullDocument.address.country': 'Australia',
                               'fullDocument.address.market': 'Sydney'
                           },
                       }
                   ];

    #. Let’s use this pipeline to filter the changes in our change stream.
       Update your existing call to ``monitorListingsUsingEventEmitter()``
       to only leave the change stream open for 30 seconds and use the
       pipeline.

       .. code-block:: javascript
       
          await monitorListingsUsingEventEmitter(client, 30000, pipeline);

    #. Save your file.
    #. Run your script by executing ``node changeStreams.js`` in your shell.
       The change stream will open for 30 seconds.
    #. Create and update sample data by executing :ref:`node changeStreamsTestData.js <node-change-streams-set-up>` in a new shell. Because the
       change stream is using the pipeline you just created, only documents
       inserted into the ``listingsAndReviews`` collection that are in the
       Sydney, Australia market will be in the change stream. Output similar
       to the following will be displayed in your first shell where you are
       running ``changeStreams.js``.

       .. _node-change-streams-agg-output:

       .. code-block:: javascript

        { _id:
            { _data:
                    '825DE67CED000000012B022C0100296E5A10046BBC1C6A9CBB4B6E9CA9447925E693EF46645F696400645DE67CED150EA2DF172344370004' },
                operationType: 'insert',
                clusterTime:
                Timestamp { _bsontype: 'Timestamp', low_: 1, high_: 1575386349 },
                fullDocument:
                { _id: 5de67ced150ea2df17234437,
                    name: 'Opera House Views',
                    summary:
                    'Beautiful apartment with views of the iconic Sydney Opera House',
                    property_type: 'Apartment',
                    bedrooms: 1,
                    bathrooms: 1,
                    beds: 1,
                    address: { market: 'Sydney', country: 'Australia' } },
                ns: { db: 'sample_airbnb', coll: 'listingsAndReviews' },
                documentKey: { _id: 5de67ced150ea2df17234437 } }
            { _id:
            { _data:
                    '825DE67CEE000000032B022C0100296E5A10046BBC1C6A9CBB4B6E9CA9447925E693EF46645F696400645DE67CEE150EA2DF1723443B0004' },
                operationType: 'insert',
                clusterTime:
                Timestamp { _bsontype: 'Timestamp', low_: 3, high_: 1575386350 },
                fullDocument:
                { _id: 5de67cee150ea2df1723443b,
                    name: 'Sydney Harbour Home',
                    bedrooms: 4,
                    bathrooms: 2.5,
                    address: { market: 'Sydney', country: 'Australia' } },
                ns: { db: 'sample_airbnb', coll: 'listingsAndReviews' },
                documentKey: { _id: 5de67cee150ea2df1723443b } }

       After 30 seconds, the following will be displayed:

       .. code-block:: sh

          Closing the change stream


    Monitor Change Stream using ChangeStream’s hasNext()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

    In the section above we used EventEmitter’s ``on()`` to monitor the
    change stream. Alternatively, we can create a ``while`` loop that waits
    for the next element in the change stream by using
    `hasNext() <http://bit.ly/Node_hasNext>`_ from MongoDB Node.js Driver’s
    `ChangeStream <http://bit.ly/Node_ChangeStream>`_ class.



    Create the Function
    ^^^^^^^^^^^^^^^^^^^

    Let’s create a function that will monitor changes in the change stream
    using ChangeStream’s ``hasNext()``.

    #. Continuing to work in ``changeStreams.js``, create an asynchronous
       function named ``monitorListingsUsingHasNext``. The function should
       have the following parameters: a connected MongoClient, a time in ms
       that indicates how long the change stream should be monitored, and an
       aggregation pipeline that the change stream will use.

       .. code-block:: javascript

          async function monitorListingsUsingHasNext(client, timeToWatch = 60000, pipeline = []) {  
            
          }

    #. Now we need to access the collection we will monitor for changes. Add
       the following code to ``monitorListingsUsingHasNext()``.

       .. code-block:: javascript

          const collection = client.db("sample_airbnb").collection("listingsAndReviews");

    #. Now we are ready to create our change stream. We can do so by using
       `Collection <http://bit.ly/Node_Collection>`_\ ’s
       `watch() <http://bit.ly/Node_watch>`_. Add the following line
       beneath the existing code in ``monitorListingsUsingHasNext()``.

       .. code-block:: javascript

          const changeStream = collection.watch(pipeline);

    #. We could choose to leave the change stream open indefinitely.
       Instead, let’s call our helper function that will set a timer and
       close the change stream. Add the following line beneath the existing
       code in ``monitorListingsUsingHasNext()``.

       .. code-block:: javascript

          closeChangeStream(timeInMs, changeStream);

    #. Now let’s create a while loop that will wait for new changes in the
       change stream. We can use ChangeStream’s
       `hasNext() <http://bit.ly/Node_hasNext>`_ inside of the while loop.
       ``hasNext()`` will return ``false`` as soon as the change stream is
       closed. ``hasNext()`` will wait to return true until a new change
       arrives in the change stream. Add the following line beneath the
       existing code in ``monitorListingsUsingHasNext()``.
    
       .. code-block:: javascript  

          while (await changeStream.hasNext()) {     
            console.log(await changeStream.next());  
          }


    Call the Function
    ^^^^^^^^^^^^^^^^^

    Now that we’ve implemented our function, let’s call it!

    #. Inside of ``main()``, replace your existing call to
       ``monitorListingsUsingEventEmitter()`` with a call to your new
       ``monitorListingsUsingHasNext()``:

       .. code-block:: javascript 

          await monitorListingsUsingHasNext(client);

    #. Save your file.
    #. Run your script by executing ``node changeStreams.js`` in your shell.
       The change stream will open for 60 seconds.
    #. Create and update sample data by executing :ref:`node changeStreamsTestData.js <node-change-streams-set-up>` in a new shell. Output similar
       to :ref:`what we saw earlier <node-change-streams-output>` 
       will be displayed in your
       first shell where you are running ``changeStreams.js``. If you run
       ``node changeStreamsTestData.js`` again before the 60 second timer
       has completed, you will see similar output again. After 60 seconds,
       the following will be displayed: 
       
       .. code-block:: sh 

          Closing the change stream


    Call the Function with an Aggregation Pipeline
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

    As we discussed earlier, sometimes you will want to use an aggregation
    pipeline to filter the changes in your change stream or transform the
    change stream event documents. Let’s pass the aggregation pipeline we
    created in an earlier section to our new function.

    #. Update your existing call to ``monitorListingsUsingHasNext()`` to
       only leave the change stream open for 30 seconds and use the
       aggregation pipeline.

       .. code-block:: javascript

          await monitorListingsUsingHasNext(client, 30000, pipeline);

    #. Save your file.
    #. Run your script by executing ``node changeStreams.js`` in your shell.
       The change stream will open for 30 seconds.
    #. Create and update sample data by executing :ref:`node changeStreamsTestData.js <node-change-streams-set-up>` in a new shell. Because the
       change stream is using the pipeline you just created, only documents
       inserted into the ``listingsAndReviews`` collection that are in the
       Sydney, Australia market will be in the change stream. Output similar
       to :ref:`what we saw earlier while using a change stream with an
       aggregation pipeline <node-change-streams-agg-output>`
       will be displayed in your first
       shell where you are running ``changeStreams.js``. After 30 seconds,
       the following will be displayed: 
       
       .. code-block:: sh 

          Closing the change stream

    Monitor Changes Stream using the Stream API
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

    In the previous two sections, we used EventEmitter’s ``on()`` and
    ChangeStreams’s ``hasNext()`` to monitor changes. Let’s examine a third
    way to monitor a change stream: using Node’s `Stream
    API <https://nodejs.org/api/stream.html>`_.


    Load the Stream Module
    ^^^^^^^^^^^^^^^^^^^^^^

    In order to use the Stream module, we will need to load it.

    #. Continuing to work in ``changeStreams.js``, load the Stream module at
       the top of the file.
       
       .. code-block:: javascript

          const stream = require('stream');


    Create the Function
    ^^^^^^^^^^^^^^^^^^^

    Let’s create a function that will monitor changes in the change stream
    using the Stream API.

    #. Continuing to work in ``changeStreams.js``, create an asynchronous
       function named ``monitorListingsUsingStreamAPI``. The function should
       have the following parameters: a connected MongoClient, a time in ms
       that indicates how long the change stream should be monitored, and an
       aggregation pipeline that the change stream will use.

       .. code-block:: javascript

         async function monitorListingsUsingStreamAPI(client, timeInMs = 60000, pipeline = []) {  }

    #. Now we need to access the collection we will monitor for changes. Add
       the following code to ``monitorListingsUsingStreamAPI()``.

       .. code-block:: javascript

          const collection = client.db("sample_airbnb").collection("listingsAndReviews");

    #. Now we are ready to create our change stream. We can do so by using
       `Collection <http://bit.ly/Node_Collection>`_\ ’s
       `watch() <http://bit.ly/Node_watch>`_. Add the following line
       beneath the existing code in ``monitorListingsUsingStreamAPI()``.

       .. code-block:: javascript

          const changeStream = collection.watch(pipeline);

    #. Now we’re ready to monitor our change stream. We’ll use
       ChangeStream’s `pipe() <http://bit.ly/Node_pipe>`_ to pull the data
       out of a readable stream and write it to the console.

       .. code-block:: javascript

          changeStream.pipe(
                new stream.Writable({
                    objectMode: true,
                    write: function (doc, _, cb) {
                        console.log(doc);
                        cb();
                    }
                 })
          );
   
    #. We could choose to leave the change stream open indefinitely.
       Instead, let’s call our helper function that will set a timer and
       close the change stream. Add the following line beneath the existing
       code in ``monitorListingsUsingStreamAPI()``.
      
       .. code-block:: javascript  

          await closeChangeStream(timeInMs, changeStream);


    Call the Function
    ^^^^^^^^^^^^^^^^^

    Now that we’ve implemented our function, let’s call it!

    #. Inside of ``main()``, replace your existing call to
       ``monitorListingsUsingHasNext()`` with a call to your new
       ``monitorListingsUsingStreamAPI()``:

       .. code-block:: javascript

          await monitorListingsUsingStreamAPI(client);

    #. Save your file.
    #. Run your script by executing ``node changeStreams.js`` in your shell.
       The change stream will open for 60 seconds.
    #. Output similar to :ref:`what we saw earlier <node-change-streams-output>` will be
       displayed in your first shell where you are running
       ``changeStreams.js``. If you run ``node changeStreamsTestData.js``
       again before the 60 second timer has completed, you will see similar
       output again. After 60 seconds, the following will be displayed:

       .. code-block:: sh

          Closing the change stream


    Call the Function with an Aggregation Pipeline
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

    As we discussed earlier, sometimes you will want to use an aggregation
    pipeline to filter the changes in your change stream or transform the
    change stream event documents. Let’s pass the aggregation pipeline we
    created in an earlier section to our new function.

    #. Update your existing call to ``monitorListingsUsingStreamAPI()`` to
       only leave the change stream open for 30 seconds and use the
       aggregation pipeline.
      
       .. code-block:: javascript

          await monitorListingsUsingHasNext(client, 30000, pipeline);

    #. Save your file.
    #. Run your script by executing ``node changeStreams.js`` in your shell.
       The change stream will open for 30 seconds.
    #. Create and update sample data by executing :ref:`node changeStreamsTestData.js <node-change-streams-set-up>` in a new shell. Because the
       change stream is using the pipeline you just created, only documents
       inserted into the ``listingsAndReviews`` collection that are in the
       Sydney, Australia market will be in the change stream. Output similar
       to :ref:`what we saw earlier while using a change stream with an
       aggregation pipeline <node-change-streams-agg-output>`
       will be displayed in your first
       shell where you are running ``changeStreams.js``. After 30 seconds,
       the following will be displayed: 
       
       .. code-block:: sh

          Closing the change stream

    .. _node-change-streams-resume:

    Resume a Change Stream
    ----------------------

    At some point, your application will likely lose the connection to the
    change stream. Perhaps a network error will occur and a connection
    between the application and the database will be dropped. Or perhaps
    your application will crash and need to be restarted (but you’re a 10x
    developer and that would never happen to you, right?).

    In those cases, you may want to resume the change stream where you
    previously left off so you don’t lose any of the change events.

    Each change stream event document contains a resume token. The Node.js
    driver automatically stores the resume token in the ``_id`` of the
    change event document.

    The application can pass the resume token when creating a new change
    stream. The change stream will include all events that happened after
    the event associated with the given resume token.

    The MongoDB Node.js driver will automatically attempt to reestablish
    connections in the event of transient network errors or elections. In
    those cases, the driver will use its cached copy of the most recent
    resume token so that no change stream events are lost.

    In the event of an application failure or restart, the application will
    need to pass the resume token when creating the change stream in order
    to ensure no change stream events are lost. Keep in mind that the driver
    will lose its cached copy of the most recent resume token when the
    application restarts, so your application should store the resume token.

    For more information and sample code for resuming change streams, see
    the `official
    documentation <https://docs.mongodb.com/manual/changeStreams/#resume-a-change-stream>`_.


    .. _node-change-streams-triggers:

    What are MongoDB Atlas Triggers?
    --------------------------------

    Change streams allow you to react immediately to changes in your
    database. If you want to constantly be monitoring changes to your
    database, ensuring that your application that is monitoring the change
    stream is always up and not missing any events is possible… but can be
    challenging. This is where MongoDB Atlas Triggers come in.

    MongoDB supports triggers in `Atlas <http://bit.ly/MDB_Atlas>`_. `Atlas
    Triggers <https://docs.atlas.mongodb.com/triggers/>`_ allow you to
    execute functions in real time based on database events (just like
    change streams) or on scheduled intervals (like a cron job). Atlas
    Triggers have a few big advantages: 
    
    * You don’t have to worry about programming the change stream. You simply program the function that will
      be executed when the database event is fired. 
    * You don’t have to worry about managing the server where your change stream code is running.
      Atlas takes care of the server management for you. 
    * You get a handy UI to configure your trigger, which means you have less code to write.

    Atlas Triggers do have a few constraints. The biggest constraint I hit
    in the past was that functions did not support module imports (i.e.
    **import** and **require**). Recently, module import capabilities were
    added in beta. To learn more about functions and their constraints, see
    the `official Stitch Function
    documentation <https://docs.mongodb.com/stitch/functions/>`_.

    .. _node-change-streams-create-trigger:

    Create a MongoDB Atlas Trigger
    ------------------------------

    Just as we did in earlier sections, let’s look for new listings in the
    Sydney, Australia market. Instead of working locally in a code editor to
    create and monitor a change stream, we’ll create a trigger in the Atlas
    web UI.

    Create a Trigger
    ~~~~~~~~~~~~~~~~

    Let’s create an Atlas Trigger that will monitor the
    ``listingsAndReviews`` collection and call a function whenever a new
    listing is added in the Sydney, Australia market.

    #.  Navigate to your project in `Atlas <http://bit.ly/MDB_Atlas>`_.
    #.  In the Services section of the left navigation pane, click
        **Triggers**.
    #.  Click **Add Trigger**. The **Add Trigger** wizard will appear.
    #.  In the **Link Cluster(s)** selection box, select your cluster that
        contains the ``sample_airbnb`` database and click **Link**. The
        changes will be deployed. The deployment may take a minute or two.
        Scroll to the top of the page to see the status.
    #.  In the **Select a cluster…** selection box, select your cluster that
        contains the ``sample_airbnb`` database.
    #.  In the **Select a database name…** selection box, select
        **sample_airbnb**.
    #.  In the **Select a collection name…** selection box, select
        **listingsAndReviews**.
    #.  In the Operation Type section, check the box beside **Insert**.
    #.  In the Function code box, replace the commented code with a call to
        log the change event. The code should now look like the following:
        
        .. code-block:: javascript

           exports = function(changeEvent) {
              console.log(JSON.stringify(changeEvent.fullDocument));  
              };

    #.  We can create a
        `$match <https://docs.mongodb.com/manual/reference/operator/aggregation/match/>`_
        statement to filter our change events just as we did earlier with
        the aggregation pipeline we passed to the change stream in our
        Node.js script. Expand the **ADVANCED (OPTIONAL)** section at the
        bottom of the page and paste the following in the **Match
        Expression** code box.
        
        .. code-block:: javascript

           {      
                "fullDocument.address.country": "Australia",      
                "fullDocument.address.market": "Sydney"  
           }

    #.  Click **Save**. The Trigger will be enabled. From that point on, the
        function to log the change event will be called whenever a new
        document in the Sydney, Australia market is inserted in the
        ``listingsAndReviews`` collection.


    Fire the Trigger
    ~~~~~~~~~~~~~~~~

    Now that we have the Trigger configured, let’s create sample data that
    will fire the trigger.

    #. Return to the shell on your local machine.
    #. Create and update sample data by executing :ref:`node changeStreamsTestData.js <node-change-streams-set-up>` in a new shell.

    View the Trigger Results
    ~~~~~~~~~~~~~~~~~~~~~~~~

    When you created the Trigger, MongoDB Atlas automatically created a
    Stitch application for you named **Triggers_StitchApp**.

    The function associated with your trigger doesn’t currently do much. It
    simply prints the change event document. Let’s view the results in the
    logs of the Stitch app associated with your trigger.

    #. Return to your browser where you are viewing your trigger in Atlas.
    #. In the Services section of the left navigation pane, click **Stitch**.
    #. In the Stitch Applications pane, click **Triggers_StitchApp**. The **Triggers_StitchApp** Stitch application will open.
    #. In the Manage section of the left navigation pane, click **Logs**.
       Two entries will be displayed in the Logs pane—one for each of the
       listings in the Sydney, Australia market that was inserted into the
       collection.
    #. Click the arrow at the beginning of each row in the Logs pane to
       expand the log entry. Here you can see the full document that was
       inserted.

    If you insert more listings in the Sydney, Australia market, you can
    refresh the Logs page to see the change events.

.. summary::

    .. _node-change-streams-wrapping-up:

    Wrapping Up
    -----------

    Today we explored four different ways to accomplish the same task of
    reacting immediately to changes in the database. We began by writing a
    Node.js script that monitored a change stream using Node.js’s Built-in
    `EventEmitter <https://nodejs.org/dist/latest-v12.x/docs/api/events.html#events_class_eventemitter>`_
    class. Next we updated the Node.js script to monitor a change stream
    using the MongoDB Node.js Driver’s
    `ChangeStream <http://bit.ly/Node_ChangeStream>`_ class. Then we
    updated the Node.js script to monitor a change stream using the `Stream
    API <https://nodejs.org/api/stream.html>`_. Finally, we created an
    Atlas trigger to monitor changes. In all four cases, we were able to use
    `$match <https://docs.mongodb.com/manual/reference/operator/aggregation/match/>`_
    to filter the change stream events.

    This post included many code snippets that built on code written in the
    `first
    post <https://www.mongodb.com/blog/post/quick-start-nodejs-mongodb--how-to-get-connected-to-your-database>`_
    of this MongoDB and Node.js Quick Start series. To get a full copy of
    the code used in today’s post, visit the `Node.js Quick Start GitHub
    Repo <https://github.com/mongodb-developer/nodejs-quickstart/blob/master/changeStreams.js>`_.

    The examples we explored today all did relatively simple things whenever
    an event was fired: they logged the change events. Change streams and
    triggers become really powerful when you start doing more in response to
    change events. For example, you might want to fire alarms, send emails,
    place orders, update other systems, or do other amazing things.

    This is the final post in the Node.js and MongoDB Quick Start Series (at
    least for now!). I hope you’ve enjoyed it! If you have ideas for other
    topics you’d like to see covered, drop a comment below.

 
    .. _node-change-streams-resources:

    Additional Resources
    --------------------

    -  `MongoDB Official Documentation: Change Streams <https://docs.mongodb.com/manual/changeStreams/>`_
    -  `MongoDB Official Documentation: Triggers <https://docs.atlas.mongodb.com/triggers/>`_
    -  `Blog Post: An Introduction to Change Streams <https://www.mongodb.com/blog/post/an-introduction-to-change-streams>`_
    -  `Video: Using Change Streams to Keep Up with Your Data <https://www.mongodb.com/presentations/using-change-streams-to-keep-up-with-your-data>`_
    -  `Video: Using Functions and Triggers <https://youtu.be/gfg2wbh5_xI>`_

 
    .. _node-change-streams-versions:

    Series Versions
    ---------------

    This blog post was created with the following application versions: 
    
    * MongoDB: 4.0 
    * MongoDB Node.js Driver: 3.3 
    * Node.js: 10.16.3

    .. _node-change-streams-series-toc:

    All posts in the Quick Start: Node.js and MongoDB series
    --------------------------------------------------------

    -  `How to connect to a MongoDB database using Node.js <https://www.mongodb.com/blog/post/quick-start-nodejs-mongodb--how-to-get-connected-to-your-database>`_
    -  `MongoDB Node.js CRUD Tutorial </quickstart/java-setup-crud-operations>`_
    -  `How to analyze your data using MongoDB’s Aggregation Framework and Node.js <https://www.mongodb.com/blog/post/quick-start-nodejs--mongodb--how-to-analyze-data-using-the-aggregation-framework>`_
    -  `How to implement transactions using Node.js <https://www.mongodb.com/blog/post/quick-start-nodejs--mongodb--how-to-implement-transactions>`_
    -  How to react to database changes with change streams and triggers (this post)
